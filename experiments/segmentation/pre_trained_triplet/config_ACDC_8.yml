batch_size: 32
n_epochs: 3000
patience: 100 #number of epochs wait until improvement
clipping: false #apply gradient clipping
min_delta: 0.005 #min delta of improvement for early stopping
verbose_train: true
num_workers: 0
n_train_samples: 1
model_name: unet_8_pretrained_triplet_ACDC # CHANGE WHEN CREATE A NEW MODEL
split_table_path: './data/split_tables/ACDC/8_split_table.json'
test_split_table_path: './data/split_tables/ACDC/test_split_table.json'
image_width: 240
image_height: 240
debug_path: './data/CV_debug/unet_8_pretrained_triplet_ACDC/'
checkpoint_path: ./data/model_weights/unet_8_pretrained_triplet_ACDC/checkpoint/ # CHANGE WHEN CREATE A NEW MODEL
model_path: ./data/model_weights/unet_8_pretrained_triplet_ACDC/ # CHANGE WHEN CREATE A NEW MODEL
dataset: 'ACDC_8'
model:
  in_channels: 1
  n_classes: 4
  n_filters_input: 16
  n_layers: 5
  dropout_rate: 0.0
  kernel_size: 3
  dilation: 3
  pre_trained_model: "./data/model_weights/encoder_triplet_ACDC/encoder_triplet_ACDC_UB_split_table_fold_0.88_1616483261.4758973"
  freeze_layers: false
  freeze_layers_delay: 50000
optimizer_name: Adam
optimizer_hparams:
  lr: 0.001
  weight_decay: 0.0
scheduler_name: ReduceLROnPlateau
scheduler_hparams:
  patience: 3000000000
  threshold: 0.02
  verbose: true
  factor: 0.2